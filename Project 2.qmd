---
title: "Project 2"
---

**Name:** Da Yea Song (dsong13\@jhmi.edu; dsong13); Amanda Kim (akim148\@jh.edu)

## Set Up

```{r}
library(dplyr)
library(ggplot2)
library(htmlwidgets)
library(purrr)
library(rvest)
library(tidyr)
library(tidycensus)
library(tidyverse)
library(wesanderson)
library(wordcloud2)
library(plotly)
```

## Part 1

1.  Choose a question to investigate. Describe what is the question you aim to answer with the data and what you want to visualize.

    **How was the income gap between men and women, measured by the difference in median income, varied across US states over the past three years?**

2.  Extract data from the `tidycensus` API. Use at least three different calls to the `tidycensus` API to extract out different datasets. For example, these could be across years, locations, or variables.

    ```{r}
    # Check variables 
    variables_2021 <- load_variables(2021, "acs1", cache = TRUE)
    head(variables_2021)
    ```

    B20017_002 male median income; B20017_005 female median income

    ```{r}

    # Call 1: Median Income by Sex for 2021
    income_2021 <- get_acs(
      geography = "state",
      variables = c(male_income = "B20017_002", female_income = "B20017_005"),
      year = 2021,
      survey = "acs1"
    )

    # Call 2: Median Income by Sex for 2021
    income_2022 <- get_acs(
      geography = "state",
      variables = c(male_income = "B20017_002", female_income = "B20017_005"),
      year = 2022,
      survey = "acs1"
    )

    # Call 3: Median Income by Sex for 2023
    income_2023 <- get_acs(
      geography = "state",
      variables = c(male_income = "B20017_002", female_income = "B20017_005"),
      year = 2023,
      survey = "acs1"
    )
    ```

3.  Clean the data. Include some form of data wrangling and data visualization using packages such as `dplyr` or `tidyr`. Other packages that might be helpful to you include `lubridate`, `stringr`, and `forcats`. You must use at least two functions from `purrr`.

    ```{r}
    # Step 1: Add year column using mutate (dplyr)
    income_2021 <- income_2021 %>% mutate(year = 2021)
    income_2022 <- income_2022 %>% mutate(year = 2022)
    income_2023 <- income_2023 %>% mutate(year = 2023)
    ```

    ```{r}
    # Step 2: Combine into one dataset using map_dfr (purrr)
    income_data <- list(income_2021, income_2022, income_2023)

    income_total <- map_dfr(income_data, ~ .x)

    print(income_total)
    ```

    ```{r}
    # Step 3: Remove moe columns using select (dplyr)
    income_total <- income_total %>%
      select(-moe)

    print(income_total)
    ```

    ```{r}
    # Step 4: Reorganize data using pivot_wider (tidyr)
    income_total <- income_total %>%
      pivot_wider(
        names_from = variable,
        values_from = c(estimate),
        names_glue = "{variable}_{.value}"
      ) %>%
      rename(
        male_income = male_income_estimate,
        female_income = female_income_estimate,
      )

    print(income_total)
    ```

    ```{r}
    # Step 5: Calculate income difference between sexes using pmap_dbl (purr)
    income_total <- income_total %>%
      mutate(income_difference = pmap_dbl(
        list(male_income, female_income),
        ~ ..1 - ..2
      ))

    print(income_total)
    ```

    ```{r}
    # Step 6: Reorder the table by year and income difference using arrange (dplyr)
    income_total <- income_total %>%
      arrange(year, income_difference)

    print(income_total)
    ```

4.  Visualize the data. Create data visualizations of your choice. However, your analysis should include at least three plots with you using at least two different `geom_*()` functions from `ggplot2` (or another package with `geom_*()` functions).

```{r}
# Plot 1: Income by Sex and States (2021-2023) using geom_bar

## Reshape the data to long format
income_total_long <- income_total %>%
  pivot_longer(cols = c(male_income, female_income), 
               names_to = "sex", 
               values_to = "income", 
               names_prefix = "sex_") 

ggplot(income_total_long, aes(x = NAME, y = income, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~year, ncol = 1) +  # Ensure facets are in one row
  labs(title = "Income by Sex and State", 
       subtitle = "Based on data from the US Census",
       caption = "Figure created by: Amanda and Da-Yea", 
       x = "U.S States", 
       y = "Median Income (USD)") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 25)) + 
  scale_fill_manual(
    values = c("female_income" = "coral", "male_income" = "salmon4"),
    labels = c("Female", "Male")
  ) +
  theme_grey() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 11, face = "bold"),
    axis.text.x = element_text(size = 6, angle = 45, hjust = 1),  
    axis.text.y = element_text(size = 8),
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 10, face = "bold"),
    legend.position = "bottom",
    panel.spacing = unit(1, "lines")
  )
```

```{r}
# Plot 2: Income Difference by Sex and States (2023) using geom_col

income_total_2023 <- income_total %>%
  filter(year == 2023)

ggplot(income_total_2023, aes(x = NAME, y = income_difference)) +  # Don't map fill to NAME
  geom_col(fill = "lightsteelblue2") +  # Set all bars to the color you want
  labs(title = "Income Difference by State", 
       subtitle = "Based on data from the US Census",
       caption = "Figure created by: Amanda and Da-Yea", 
       x = "U.S States", 
       y = "Income Difference (USD)") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 25)) +  # Wrap state names if needed
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 11, face = "bold"),
    axis.text.x = element_text(size = 7, angle = 45, hjust = 1),  
    axis.text.y = element_text(size = 8),
    panel.spacing = unit(1, "lines")
)
```

```{r}
# Plot 3: Income Difference Across Years by State using geom_line

p <- ggplot(income_total, aes(x = year, y = income_difference, color = NAME, group = NAME)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(
    title = "Income Difference Across Years by State",
    subtitle = "Based on data from the US Census",
    caption = "Figure created by: Amanda and Da-Yea", 
    x = "Year",
    y = "Income Difference (USD)"
  ) +
  scale_y_continuous(labels = scales::comma) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12,face = "bold"),
    axis.text.x = element_text(size = 6),
    axis.text.y = element_text(size = 6),
    strip.text = element_text(size = 8), 
    legend.position = "none"
  ) +
  facet_wrap(~ NAME, ncol = 7) 

interactive_plot <- ggplotly(p) %>%
  layout(
    annotations = list(
      # Subtitle annotation
      list(
        x = 0.5, y = 1.02, text = "Based on data from the US Census", 
        showarrow = FALSE, xref = "paper", yref = "paper", 
        xanchor = "center", yanchor = "bottom", font = list(size = 12)
      ),
      # Caption annotation
      list(
        x = 0.8, y = 0, text = "Figure created by: Amanda and Da-Yea", 
        showarrow = FALSE, xref = "paper", yref = "paper", 
        xanchor = "center", yanchor = "top", font = list(size = 10)
      )
    )
  )

interactive_plot
```

::: callout-note
Line graph above is an interactive plot to help address the congestion of data. Use your mouse to hover over each state graph to identify the income difference between men and women for that specific state.
:::

6.  Report your findings. Provide a paragraph summarizing your methods and key findings. Include any limitations or potential biases in pulling data from the API or the analysis. Be sure to comment and organize your code so is easy to understand what you are doing.

    To analyze income disparities between men and women across U.S. states, data from the U.S. Census Bureau was retrieved through the API, cleaned, and prepared for visualization in R. The primary measure was the median income difference between men and women in each state, which was assessed over recent years. The data was first visualized in a bar graph, with each bar representing male and female median income by state. We then calculated the median income difference between male and female. We then created a bar graph for each state indicating the median income difference. This visual analysis highlighted that states like Wyoming, Connecticut, and Massachusetts exhibited some of the largest income gaps, while states like Alaska showed smaller disparities. Lastly, we then created an interactive line graph to highlight the income difference across 2021-2023. Several limitations were considered in the analysis. First, there may be inherent biases or discrepancies in the income data collected by the U.S. Census Bureau, as survey responses can vary, and certain demographic groups may be underrepresented. Additionally, the analysis focuses solely on median income, which may not capture income variations within each gender group or across different industries and job types. Lastly, while the API simplifies data access, inconsistencies in data updates or changes in variable definitions could impact the accuracy of the findings.

    ***Data cleaning*****:** <br> - `mutate()` from dplyr to create year column <br> - `map_dfr()` from purrr to combine datasets <br> - `select()` from dplyr to remove columns <br> - `pivot_wider()` from tidyr to reorganize data <br> - `pmap_dbl()` from purrr to calculate income difference <br> - `arrange()` from dplyr to reorder the table <br><br> ***Visualize*****:** <br> - `geom_bar()` to plot the income by sex and states (2021-2023) <br> - `geom_col()` to plot income difference by sex and states (2023) <br> - `geom_line()` to plot income differences across years and state

## Part 2

In this part, you and your partner will use the `rvest` package to scrape data from a website, wrangle and analyze the data, and summarize your findings.

1.  Choose a website to scrape. Select a website with structured data in HTML tables or well-defined sections. Some examples could include:

    -   A movie database like IMDb or Rotten Tomatoes (scraping movie titles, ratings, release years, etc.)

    -   A job listing site like Indeed or LinkedIn (scraping job titles, companies, and locations)

    -   A sports statistics site like ESPN or Baseball Reference (scraping team statistics, player info, etc.)

    ```{r}
    # Michelin starred restaurants in New York City 
    url <- "https://en.wikipedia.org/wiki/List_of_Michelin-starred_restaurants_in_New_York_City"
    ```

2.  Extract data with `rvest`. Here, you will want to identify the specific HTML elements or CSS selectors containing the data. Then, use `rvest` functions like `read_html()`, `html_elements()`, and `html_text()` or `html_table()` to retrieve the data.

    ```{r}
    # Extract data (read_html, html_elements, html_table)
    table <- read_html(url) %>%
      html_elements("table")

    michelin_table <- table[[1]] %>% 
      html_table(fill = TRUE)

    head(michelin_table)
    ```

3.  Clean the data. Next, perform some basic wrangling, such as remove extra whitespace, handle missing values, and convert data types as needed. You might find the functions from `dplyr` or `tidyr` useful for any additional transformations, such as renaming columns, filtering rows, or creating new variables.

    ```{r}
    # Step 1: Remove row if Cuisine or Borough/Country is NA using filter (dplyr)
    michelin_table <- michelin_table %>%
      filter(!is.na(Cuisine) & 
               !str_trim(Cuisine) == "" & 
             !is.na(`Borough/County - Neighborhood`) & 
               !str_trim(`Borough/County - Neighborhood`) == "")
    ```

    ```{r}
    # Step 2: Create new variable on Open/Closes Status using mutate (dplyr)
    michelin_table <- michelin_table %>%
      mutate(status = case_when(
        grepl("Closed|Temporarily Closed", `2023`) ~ "Closed",
        TRUE ~ "Open"
      ))

    head(michelin_table)
    ```

    ```{r}
    # Step 3: Create new variable on Neighborhood using mutate (dplyr)
    michelin_table <- michelin_table %>%
      mutate(neighborhood = 
               sapply(strsplit(as.character(`Borough/County - Neighborhood`), " - "), `[`, 1))

    head(michelin_table)
    ```

    ```{r}
    # Step 4: Create new variable on Cuisine using mutate (dplyr)
    michelin_table <- michelin_table %>%
      mutate(cuisine = 
               sapply(strsplit(as.character(Cuisine), ", "), `[`, 1))

    head(michelin_table)
    ```

    ```{r}
    # Step 5: Remove columns using select (dplyr)
    michelin_table <- michelin_table %>%
      select(-Cuisine, -`Borough/County - Neighborhood`, -`2021`, -`2022`, -`2023`, -`2024`)

    head(michelin_table)
    ```

    ```{r}
    # Step 6: Arrange by neighborhood using arrange (dplyr)
    michelin_table <- michelin_table %>%
      arrange('neighborhood')

    head(michelin_table)
    ```

    ```{r}
    # Step 7: Remove Reference variable 
    michelin_table <- michelin_table %>% 
      filter(cuisine != "Reference")
    ```

    ```{r}
    # Step 8: Remove whitespace from variables 
    michelin_table <- michelin_table %>% 
      mutate(across(where(is.character), str_trim))
    ```

4.  Analyze the data. Perform a simple analysis of your choice. For example, you could

    -   Count how many times specific words or themes appear.

        ```{r}
        cuisine_wordcloud <- data.frame(
          word = table(michelin_table$cuisine),  
          freq = as.integer(table(michelin_table$cuisine)) 
        )

        saveWidget(
          wordcloud2(cuisine_wordcloud, 
                     color = wes_palette("GrandBudapest2"),
                     backgroundColor = "lavenderblush", 
                     size = 0.5, 
                     minRotation = 0, maxRotation = 0), 
          "cuisine_wordcloud.html"  
        )

        htmltools::tags$iframe(src = "cuisine_wordcloud.html", width = "100%", height = "500px")
        ```

    -   Create a summary statistic (e.g., average rating, job salary, team win percentage).

    ```{r}
    # Number of michelin-starred restaurants in each neighborhood in NY
    neighborhood_count <- michelin_table %>%
      count(neighborhood, sort = TRUE)

    # Print the results
    print(neighborhood_count)
    ```

    ```{r}
    # Count the number of restaurants by Cuisine in all of New York
    cuisine_count_ny <- michelin_table %>%
      count(cuisine, sort = TRUE)

    # View the result
    print(cuisine_count_ny)
    ```

    ```{r}
    # Count the number of restaurants by Cuisine for each Neighborhood
    cuisine_by_neighborhood <- michelin_table %>%
      group_by(neighborhood, cuisine) %>%
      summarise(number_of_restaurants = n(), .groups = "drop")

    # View the result
    print(cuisine_by_neighborhood)
    ```

    ```{r}
    #Filter for closed restaurants and count by neighborhood
    closed_restaurants_by_neighborhood <- michelin_table %>%
      filter(status == "Closed") %>%  
      count(neighborhood, sort = TRUE) %>% 
      rename(number_of_closed_restaurants = n)

    # View the results
    print(closed_restaurants_by_neighborhood)
    ```

    -   Create a data visualization (e.g., bar chart, histogram) of an interesting metric.

```{r}
#Counting Restaurants by Neighborhood
ggplot(neighborhood_count, aes(x = reorder(neighborhood, n), y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Number of Restaurants by Neighborhood",
       subtitle = "In New York City",
       caption = "Graphed by Da Yea Song & Amanda Kim",
       x = "Neighborhood",
       y = "Number of Restaurants") + 
   theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 11, face = "bold")
  )
```

```{r}
#Cuisine Distribution Across NYC:
ggplot(cuisine_count_ny, aes(x = reorder(cuisine, -n), y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Cuisine Distribution",
    subtitle = "In New York City",
    caption = "Graphed by Da Yea Song & Amanda Kim",
    x = "Cuisine",
    y = "Number of Restaurants"
  ) +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 11, face = "bold")
  )
```

```{r}
ggplot(cuisine_by_neighborhood, aes(x = cuisine, y = number_of_restaurants, fill = number_of_restaurants)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ neighborhood, ncol = 2) + # Facet by neighborhood
  labs(
    title = "Cuisine Distribution by Neighborhood",
    subtitle = "In New York City",
    caption = "Graphed by Da Yea Song & Amanda Kim",
    x = "Cuisine",
    y = "Number of Restaurants"
  ) +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 11, face = "bold"), 
    axis.text.x = element_text(angle = 90, hjust = 1) 
  )
```

```{r}
#Closed Restaurants by Neighborhood
ggplot(closed_restaurants_by_neighborhood, 
       aes(x = reorder(neighborhood, -number_of_closed_restaurants), 
           y = number_of_closed_restaurants)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Closed Michelin-Starred Restaurants by Neighborhood",
       subtitle = "In New York City",
       caption = "Graphed by Da Yea Song & Amanda Kim",
       x = "Neighborhood",
       y = "Number of Closed Restaurants") + 
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 11, face = "bold")
  )
```

5.  Report your findings. Provide a paragraph summarizing your methods and key findings. Include any limitations or potential biases in your scraping or analysis. Be sure to comment and organize your code so is easy to understand what you are doing.

    Based on our data, Japanese and Contemporary cuisine have the largest presence across New York City, with Korean, French, and Italian following. To pull this information from the Wikipedia page, we ran a simple code with the count() function and assigned it to a new variable called “cuisine_count_ny,” which gave us the number of restaurants for each cuisine category across all of New York City. Based on the table/information provided in the Wikipedia page, we were interested in understanding how many Michelin-starred restaurants in New York City closed in the 2023. To pull this information, we assigned each restaurant a status of “open” or “closed.” For any of the rows that had a blank space or a dash on the Wikipedia page, this was coded as “open.” Any restaurants that were indicated as “closed” or “temporarily closed” was coded as “closed.” The bar graph titled “Closed Michelin-Starred Restaurants by Neighborhood” shows that the only closed restaurants in 2023 were from Brooklyn and Manhattan, with majority of the closed restaurants coming from Manhattan. Some limitations or potential biases in web scrapping may come from the lack of data completeness (the Wiki page might not have listed all the Michelin-starred restaurants or if the data might not be up-to-date, especially for recently closed restaurants). There could also be categorization bias, where the cuisine and location categorization may vary or be inconsistent on the webpage. There also might be scraping errors, where errors in parsing HTML can result in missing or duplicated entries.

    ***Extracting data*****:** <br> - `read_html()` <br> - `html_table()` <br> - `read_html()`<br> <br> ***Data cleaning*****:** <br> - `mutate()` from dplyr to create new variable <br> - `select()` from dplyr to remove columns <br> - `arrange()` from dplyr to arrange by neighborhood <br> - `filter()` from dplyr to find and remove row <br> <br> ***Data analysis*****:** <br> - `wordcloud2()` to count how many times specific words appear <br> - `count()` to count the number of michelin-starred restaurants <br> - `summarise()` to count the number of restaurants by cuisine for each neighborhood <br> <br> ***Data visualization*****:** <br> - `geom_bar()` to plot the number of restaurants by neighborhood <br> - `geom_bar()` to plot the number of cuisine distribution across NYC, to plot the number of closed restaurants by neighborhood
